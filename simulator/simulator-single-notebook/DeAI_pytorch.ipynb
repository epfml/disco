{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple decentralized training\n",
    "\n",
    "We train a CNN (LeNet) on decntralized MNIST datset. \n",
    "\n",
    "The data is split either randomly (iid) or according to label (non-iid). The communication graph can be also arbitarily set. Each node can perform multiple updates before communicating.\n",
    "\n",
    "To try on colab: https://colab.research.google.com/drive/1DT4EaeEk9AuaFWMRaNkFEyQ9e-SphlUG?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sESj8k1APL8E"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(2048, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    \"\"\"Train a client_model on the train_loder data.\"\"\"\n",
    "    client_model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def diffuse_params(client_models, communication_matrix):\n",
    "    \"\"\"Diffuse the models with their neighbors.\"\"\"\n",
    "    if client_models:\n",
    "      client_state_dicts = [model.state_dict() for model in client_models]\n",
    "      keys = client_state_dicts[0].keys()\n",
    "    for model, weights in zip(client_models, communication_matrix):\n",
    "        neighbors = np.nonzero(weights)[0]\n",
    "        model.load_state_dict(\n",
    "            {\n",
    "                key: torch.stack(\n",
    "                    [weights[j]*client_state_dicts[j][key] for j in neighbors],\n",
    "                    dim=0,\n",
    "                ).sum(0) / weights.sum() \n",
    "                for key in keys\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "def average_models(global_model, client_models):\n",
    "    \"\"\"Average models across all clients.\"\"\"\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k] for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    \"\"\"Compute loss and accuracy of a single model on a data_loader.\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    loss /= len(data_loader.dataset)\n",
    "    acc = correct / len(data_loader.dataset)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "def evaluate_many_models(models, data_loader):\n",
    "  \"\"\"Compute average loss and accuracy of multiple models on a data_loader.\"\"\"\n",
    "  num_nodes = len(models)\n",
    "  losses = np.zeros(num_nodes)\n",
    "  accuracies = np.zeros(num_nodes)\n",
    "  for i in range(num_nodes):\n",
    "    losses[i], accuracies[i] = evaluate_model(models[i], data_loader)\n",
    "  return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHwoRWubPL8M",
    "outputId": "925d68c8-95d0-4b9a-f353-1dcc94054dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 0.12 | average test loss 0.145 | average test acc: 0.957\n",
      "1-th round\n",
      "average train loss 0.0785 | average test loss 0.0896 | average test acc: 0.972\n",
      "2-th round\n",
      "average train loss 0.155 | average test loss 0.0651 | average test acc: 0.978\n",
      "3-th round\n",
      "average train loss 0.0995 | average test loss 0.0568 | average test acc: 0.981\n",
      "4-th round\n",
      "average train loss 0.0717 | average test loss 0.05 | average test acc: 0.984\n"
     ]
    }
   ],
   "source": [
    "# IID case: all the clients have images of all the classes\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_clients = 5\n",
    "num_rounds = 5\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "# Communication matrix\n",
    "# For now restricted to doubly stochastic matrices.\n",
    "comm_matrix = np.ones((num_clients, num_clients)) / num_clients\n",
    "# comm_matrix = np.eye(num_clients)\n",
    "\n",
    "# Creating decentralized datasets\n",
    "\n",
    "traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                       )\n",
    "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        ), batch_size=10*batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "global_model = Net().cuda()\n",
    "client_models = [Net().cuda() for _ in range(num_clients)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "\n",
    "# Runnining Decentralized training\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in range(num_clients):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[i], epoch=epochs)\n",
    "    \n",
    "    # diffuse params across neighbors\n",
    "    diffuse_params(client_models, comm_matrix)\n",
    "\n",
    "    # evaluate\n",
    "    test_losses, accuracies = evaluate_many_models(client_models, test_loader)\n",
    "    \n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | average test loss %0.3g | average test acc: %0.3f' % (loss / num_clients, test_losses.mean(), accuracies.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NL8mMJcePL8S",
    "outputId": "c051b374-61c1-440d-a0a9-1eb0bd82a318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 0.465 | average test loss 2.27 | average test acc: 0.233\n",
      "1-th round\n",
      "average train loss 0.121 | average test loss 2.55 | average test acc: 0.263\n",
      "2-th round\n",
      "average train loss 0.0327 | average test loss 2.7 | average test acc: 0.353\n",
      "3-th round\n",
      "average train loss 0.0271 | average test loss 2.71 | average test acc: 0.418\n",
      "4-th round\n",
      "average train loss 0.0517 | average test loss 2.76 | average test acc: 0.427\n"
     ]
    }
   ],
   "source": [
    "# NON-IID case: every client has images of two categories chosen from [0, 1], [2, 3], [4, 5], [6, 7], or [8, 9].\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_clients = 5\n",
    "num_rounds = 5\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Communication matrix\n",
    "# For now restricted to doubly stochastic matrices.\n",
    "comm_matrix = np.ones((num_clients, num_clients)) / num_clients\n",
    "# comm_matrix = np.eye(num_clients)\n",
    "\n",
    "# Creating decentralized datasets\n",
    "\n",
    "traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                       )\n",
    "target_labels = torch.stack([traindata.targets == i for i in range(10)])\n",
    "target_labels_split = []\n",
    "for i in range(5):\n",
    "    target_labels_split += torch.split(torch.where(target_labels[(2 * i):(2 * (i + 1))].sum(0))[0], int(60000 / num_clients))\n",
    "traindata_split = [torch.utils.data.Subset(traindata, tl) for tl in target_labels_split]\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        ), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "global_model = Net().cuda()\n",
    "client_models = [Net().cuda() for _ in range(num_clients)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "\n",
    "# Runnining Decentralized training\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in range(num_clients):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[i], epoch=epochs)   \n",
    "    \n",
    "    # diffuse params across neighbors\n",
    "    diffuse_params(client_models, comm_matrix)\n",
    "\n",
    "    # evaluate\n",
    "    test_losses, accuracies = evaluate_many_models(client_models, test_loader)\n",
    "    \n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | average test loss %0.3g | average test acc: %0.3f' % (loss / num_clients, test_losses.mean(), accuracies.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tR6rSf5SPL8X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeAI_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}